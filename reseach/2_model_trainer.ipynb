{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db20692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/leksman/Desktop/EEEEE/end_to_end_plant_vilage_project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309fa90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "   dir_root: Path\n",
    "   train_data_root: Path\n",
    "   trained_model: Path\n",
    "   num_epoch: int\n",
    "   learning_rate: float\n",
    "   num_classes: int\n",
    "   batch_size: int\n",
    "   num_workers: int\n",
    "   shuffle: bool\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the config \n",
    "from scr.Plant_Vilage.constants import SCHEMA_FILE_PATH,PARAMS_FILE_PATH,CONFIG_FILE_PATH\n",
    "import scr.Plant_Vilage.utils.common as common\n",
    "create_diretory = common.create_directory \n",
    "read_yaml = common.read_yaml\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_file_path: Path = CONFIG_FILE_PATH,\n",
    "        schema_file_path: Path = SCHEMA_FILE_PATH,\n",
    "        params_file_path: Path = PARAMS_FILE_PATH\n",
    "    ):\n",
    "       \n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.schema = read_yaml(schema_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        create_diretory([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "        params = self.params.model_params\n",
    "        create_diretory([config.dir_root])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            dir_root= config.dir_root,\n",
    "            train_data_root=config.train_data_root,\n",
    "            trained_model=config.trained_model,\n",
    "            num_epoch = params.num_epoch,\n",
    "            learning_rate=params.learning_rate,\n",
    "            num_classes=params.num_classes,\n",
    "            batch_size=params.batch_size,\n",
    "            num_workers=params.num_workers,\n",
    "            shuffle=params.shuffle\n",
    "    \n",
    "\n",
    "        )\n",
    "\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76770a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.functional import F\n",
    "import gc\n",
    "from scr.Plant_Vilage import logger\n",
    "from scr.Plant_Vilage.utils.common import save_bin\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self,config:ModelTrainerConfig):\n",
    "        self.config = config\n",
    "        self.device =  torch.device(\"cuda\")\n",
    "\n",
    "    def train_cnn_model(self):\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),                     # Resize images\n",
    "        transforms.RandomHorizontalFlip(p=0.5),            # Randomly flip images\n",
    "        transforms.RandomRotation(degrees=15),             # Random rotation\n",
    "        #transforms.ColorJitter(brightness=0.2),  # Add jitter\n",
    "        transforms.ToTensor(),                             # Convert to tensor [C, H, W] in [0, 1]\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5],          # Normalize with 0â€“1 range scaling\n",
    "                            std=[0.5, 0.5, 0.5])\n",
    "                ])\n",
    "\n",
    "\n",
    "        train_dataset = datasets.ImageFolder(root=self.config.train_data_root,transform=transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size, shuffle=self.config.shuffle, num_workers=self.config.num_workers)\n",
    "\n",
    "        class BasicBlock(nn.Module):\n",
    "            def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "                super().__init__()\n",
    "                self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                                    stride=stride, padding=1, bias=False)\n",
    "                self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "                self.relu = nn.ReLU(inplace=True)\n",
    "                self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                                    stride=1, padding=1, bias=False)\n",
    "                self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "                self.downsample = downsample\n",
    "\n",
    "            def forward(self, x):\n",
    "                identity = x\n",
    "\n",
    "                out = self.relu(self.bn1(self.conv1(x)))\n",
    "                out = self.bn2(self.conv2(out))\n",
    "\n",
    "                if self.downsample:\n",
    "                    identity = self.downsample(x)\n",
    "\n",
    "                out += identity\n",
    "                out = self.relu(out)\n",
    "\n",
    "                return out\n",
    "\n",
    "        class ResNetLike(nn.Module):\n",
    "            def __init__(self, num_classes=1):\n",
    "                super().__init__()\n",
    "                self.in_channels = 64\n",
    "                self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "                self.bn1 = nn.BatchNorm2d(64)\n",
    "                self.relu = nn.ReLU(inplace=True)\n",
    "                self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "                self.layer1 = self._make_layer(64, 2)\n",
    "                self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "                self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "                self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "                self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "                self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "            def _make_layer(self, out_channels, blocks, stride=1):\n",
    "                downsample = None\n",
    "                if stride != 1 or self.in_channels != out_channels:\n",
    "                    downsample = nn.Sequential(\n",
    "                        nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                    )\n",
    "\n",
    "                layers = [BasicBlock(self.in_channels, out_channels, stride, downsample)]\n",
    "                self.in_channels = out_channels\n",
    "                for _ in range(1, blocks):\n",
    "                    layers.append(BasicBlock(out_channels, out_channels))\n",
    "\n",
    "                return nn.Sequential(*layers)\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = self.relu(self.bn1(self.conv1(x)))  # [B, 64, H/2, W/2]\n",
    "                x = self.pool(x)                        # [B, 64, H/4, W/4]\n",
    "                x = self.layer1(x)                      # -> [B, 64, H/4, W/4]\n",
    "                x = self.layer2(x)                      # -> [B, 128, H/8, W/8]\n",
    "                x = self.layer3(x)                      # -> [B, 256, H/16, W/16]\n",
    "                x = self.layer4(x)                      # -> [B, 512, H/32, W/32]\n",
    "                x = self.global_pool(x)                 # -> [B, 512, 1, 1]\n",
    "                x = torch.flatten(x, 1)                 # -> [B, 512]\n",
    "                x = self.fc(x)                          # -> [B, num_classes]\n",
    "                return x\n",
    "            \n",
    "\n",
    "\n",
    "        def get_model_optimizer():\n",
    "            net = ResNetLike(num_classes=38)              # Make sure num_classes matches your dataset\n",
    "            lossFun = nn.CrossEntropyLoss()               # For multi-class classification\n",
    "            optimizer = torch.optim.Adam(net.parameters(), lr=self.config.learning_rate)\n",
    "            return net, optimizer, lossFun\n",
    "        \n",
    "\n",
    "        def train_model(x_y_train_loader, device):\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            net, optimizer, lossFun = get_model_optimizer()\n",
    "            net.to(device)\n",
    "\n",
    "            num_epoch = self.config.num_epoch\n",
    "            train_acc = np.zeros(num_epoch)\n",
    "            train_loss = np.zeros(num_epoch)\n",
    "            accumulation_step = 16\n",
    "\n",
    "            for epoch in range(num_epoch):\n",
    "                net.train()\n",
    "                optimizer.zero_grad()\n",
    "                batch_loss = []\n",
    "                batch_acc = []\n",
    "\n",
    "                for i, (X, y) in enumerate(x_y_train_loader):\n",
    "                    # Flatten image input for FNN\n",
    "                    X = X.to(device)  # (batch_size, 3*224*224)\n",
    "                    y = y.to(device).long()  # CrossEntropyLoss expects LongTensor class indices\n",
    "\n",
    "                    y_pred = net(X)\n",
    "                    pred_labels = y_pred.argmax(dim=1)     # Get predicted class indices\n",
    "                    acc = (pred_labels == y).float().mean().item()\n",
    "                    batch_acc.append(acc)\n",
    "\n",
    "                    loss = lossFun(y_pred, y)\n",
    "                    loss = loss / accumulation_step\n",
    "                    batch_loss.append(loss.item() * accumulation_step)  # Undo scaling for logging\n",
    "\n",
    "                    loss.backward()\n",
    "\n",
    "                    if (i + 1) % accumulation_step == 0 or (i + 1) == len(x_y_train_loader):\n",
    "                        optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                train_acc[epoch] = np.mean(batch_acc)\n",
    "                train_loss[epoch] = np.mean(batch_loss)\n",
    "\n",
    "                \n",
    "\n",
    "                logger.info(f\"Epoch {epoch+1}/{num_epoch} | \"\n",
    "                    f\"Train Loss: {train_loss[epoch]:.4f}, Train Acc: {train_acc[epoch]:.4f}\")\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "            torch.save(net.state_dict(),self.config.trained_model)\n",
    "            logger.info(f\"Plant Vilage Modeled SUcessfully the trained model is located at {self.config.trained_model}\")\n",
    "\n",
    "\n",
    "        train_model(x_y_train_loader=train_loader,device=self.device)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9920fc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-15 11:51:05,802: INFO: common: YAML file loaded successfully from: config_yaml/config.yaml:]\n",
      "[2025-09-15 11:51:05,804: INFO: common: YAML file loaded successfully from: schema.yaml:]\n",
      "[2025-09-15 11:51:05,807: INFO: common: YAML file loaded successfully from: params.yaml:]\n",
      "[2025-09-15 11:51:05,809: INFO: common: Created directory at: artifacts:]\n",
      "[2025-09-15 11:51:05,810: INFO: common: Created directory at: artifacts/model_trainer:]\n"
     ]
    },
    {
     "ename": "BoxKeyError",
     "evalue": "\"'ConfigBox' object has no attribute 'num_epoch'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/box.py:594\u001b[0m, in \u001b[0;36mbox.box.Box.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_epoch'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/box.py:633\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/box.py:621\u001b[0m, in \u001b[0;36mbox.box.Box.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mBoxKeyError\u001b[0m: \"'num_epoch'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/box.py:635\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConfigBox' object has no attribute 'num_epoch'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/config_box.py:29\u001b[0m, in \u001b[0;36mbox.config_box.ConfigBox.__getattr__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/box.py:649\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mBoxKeyError\u001b[0m: \"'ConfigBox' object has no attribute 'num_epoch'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/box.py:594\u001b[0m, in \u001b[0;36mbox.box.Box.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_epoch'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/box.py:633\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/box.py:621\u001b[0m, in \u001b[0;36mbox.box.Box.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mBoxKeyError\u001b[0m: \"'num_epoch'\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/box.py:635\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConfigBox' object has no attribute 'num_epoch'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBoxKeyError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     train_cnn_model\u001b[38;5;241m.\u001b[39mtrain_cnn_model()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      2\u001b[0m     config \u001b[38;5;241m=\u001b[39m ConfigurationManager()\n\u001b[0;32m----> 3\u001b[0m     model_trainer_config \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_trainer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     train_cnn_model \u001b[38;5;241m=\u001b[39m ModelTrainer(config\u001b[38;5;241m=\u001b[39mmodel_trainer_config)\n\u001b[1;32m      5\u001b[0m     train_cnn_model\u001b[38;5;241m.\u001b[39mtrain_cnn_model()\n",
      "Cell \u001b[0;32mIn[3], line 31\u001b[0m, in \u001b[0;36mConfigurationManager.get_model_trainer_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mmodel_params\n\u001b[1;32m     25\u001b[0m create_diretory([config\u001b[38;5;241m.\u001b[39mdir_root])\n\u001b[1;32m     27\u001b[0m model_trainer_config \u001b[38;5;241m=\u001b[39m ModelTrainerConfig(\n\u001b[1;32m     28\u001b[0m     dir_root\u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mdir_root,\n\u001b[1;32m     29\u001b[0m     train_data_root\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrain_data_root,\n\u001b[1;32m     30\u001b[0m     trained_model\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtrained_model,\n\u001b[0;32m---> 31\u001b[0m     num_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_epoch\u001b[49m,\n\u001b[1;32m     32\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mlearning_rate,\n\u001b[1;32m     33\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mnum_classes,\n\u001b[1;32m     34\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m     35\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mnum_workers,\n\u001b[1;32m     36\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mshuffle\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_trainer_config\n",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/config_box.py:31\u001b[0m, in \u001b[0;36mbox.config_box.ConfigBox.__getattr__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/conda/envs/mycondaenv/lib/python3.10/site-packages/box/box.py:649\u001b[0m, in \u001b[0;36mbox.box.Box.__getattr__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mBoxKeyError\u001b[0m: \"'ConfigBox' object has no attribute 'num_epoch'\""
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    train_cnn_model = ModelTrainer(config=model_trainer_config)\n",
    "    train_cnn_model.train_cnn_model()\n",
    "except Exception as e:\n",
    "    raise e    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycondaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
