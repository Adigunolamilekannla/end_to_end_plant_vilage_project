{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa9344c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3d3204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/leksman/Desktop/EEEEE/end_to_end_plant_vilage_project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53a5081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelEvaluationConfig:\n",
    "    dir_root: Path\n",
    "    test_data_root: Path\n",
    "    load_trained_model: Path\n",
    "    num_epoch: int\n",
    "    learning_rate: float\n",
    "    num_classes: int\n",
    "    batch_size: int\n",
    "    num_workers: int\n",
    "    shuffle: bool\n",
    "    classification_report_loc: Path\n",
    "    mlflow_url: str\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886626ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scr.Plant_Vilage.constants import SCHEMA_FILE_PATH,PARAMS_FILE_PATH,CONFIG_FILE_PATH\n",
    "import scr.Plant_Vilage.utils.common as common\n",
    "create_diretory = common.create_directory \n",
    "read_yaml = common.read_yaml\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_file_path: Path = CONFIG_FILE_PATH,\n",
    "        schema_file_path: Path = SCHEMA_FILE_PATH,\n",
    "        params_file_path: Path = PARAMS_FILE_PATH\n",
    "    ):\n",
    "       \n",
    "        self.config = read_yaml(config_file_path)\n",
    "        self.schema = read_yaml(schema_file_path)\n",
    "        self.params = read_yaml(params_file_path)\n",
    "        create_diretory([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation\n",
    "        params = self.params.model_params\n",
    "        create_diretory([config.dir_root])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            dir_root= config.dir_root,\n",
    "            load_trained_model=config.load_trained_model,\n",
    "            num_epoch = params.num_epoch,\n",
    "            learning_rate=params.learning_rate,\n",
    "            num_classes=params.num_classes,\n",
    "            batch_size=params.batch_size,\n",
    "            num_workers=params.num_workers,\n",
    "            shuffle=params.shuffle,\n",
    "            classification_report_loc= config.classification_report_loc,\n",
    "            test_data_root=config.test_data_root,\n",
    "            mlflow_url=config.mlflow_url\n",
    "            \n",
    "    \n",
    "\n",
    "        )\n",
    "\n",
    "        return model_evaluation_config\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e61eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-16 02:40:15,534: INFO: utils: NumExpr defaulting to 16 threads.:]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import mlflow\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import os\n",
    "from scr.Plant_Vilage.components.model_trainer import get_model_optimizer\n",
    "\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://dagshub.com/leksman/end_to_end_plant_vilage_project.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"leksman\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"38aba5d8d599d1c5648f9c3d7aa353c04ce2c9f9\" \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, config:ModelEvaluationConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        # Transforms\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                 std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "        # Dataset + loader\n",
    "        test_dataset = datasets.ImageFolder(\n",
    "            root=self.config.test_data_root,\n",
    "            transform=transform\n",
    "        )\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=self.config.batch_size,\n",
    "            shuffle=self.config.shuffle,\n",
    "            num_workers=self.config.num_workers\n",
    "        )\n",
    "\n",
    "        # Load model\n",
    "        model, optimizer, lossFun = get_model_optimizer()\n",
    "        model.load_state_dict(torch.load(self.config.load_trained_model, map_location=self.device, weights_only=True))\n",
    "        model.to(self.device)\n",
    "    \n",
    "\n",
    "        # MLflow setup\n",
    "        mlflow.set_registry_uri(self.config.mlflow_url)\n",
    "        tracking_url_type = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        # Evaluation\n",
    "        correct, total = 0, 0\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        total_loss = 0.0\n",
    "        all_labels, all_preds = [], []\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for X_val, y_val in test_loader:\n",
    "                    X_val = X_val.to(self.device)\n",
    "                    y_val = y_val.to(self.device).long()\n",
    "\n",
    "                    # Forward\n",
    "                    y_pred = model(X_val)\n",
    "\n",
    "                    # Loss\n",
    "                    loss = criterion(y_pred, y_val)\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                    # Predictions\n",
    "                    pred_labels = y_pred.argmax(dim=1)\n",
    "                    correct += (pred_labels == y_val).sum().item()\n",
    "                    total += y_val.size(0)\n",
    "\n",
    "                    # Collect for classification report\n",
    "                    all_labels.extend(y_val.cpu().numpy())\n",
    "                    all_preds.extend(pred_labels.cpu().numpy())\n",
    "\n",
    "            # Metrics\n",
    "            accuracy = correct / total\n",
    "            avg_loss = total_loss / len(test_loader)\n",
    "\n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"test_loss\", avg_loss)\n",
    "\n",
    "            # Classification report\n",
    "            report_dict = classification_report(\n",
    "                all_labels,\n",
    "                all_preds,\n",
    "                target_names=test_dataset.classes,\n",
    "                output_dict=True\n",
    "            )\n",
    "\n",
    "            # Save classification report as CSV\n",
    "            report_df = pd.DataFrame(report_dict).transpose()\n",
    "            report_csv_path =  self.config.classification_report_loc\n",
    "            report_df.to_csv(report_csv_path, index=True)\n",
    "\n",
    "            # Log report file to MLflow\n",
    "            mlflow.log_artifact(report_csv_path)\n",
    "\n",
    "            if tracking_url_type != \"file\":\n",
    "                # Log model itself\n",
    "                mlflow.pytorch.log_model(model, \"cnn_model\")\n",
    "            else:\n",
    "                mlflow.pytorch.log_model(model)\n",
    "\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f7d029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-16 02:40:17,207: INFO: common: YAML file loaded successfully from: config_yaml/config.yaml:]\n",
      "[2025-09-16 02:40:17,210: INFO: common: YAML file loaded successfully from: schema.yaml:]\n",
      "[2025-09-16 02:40:17,213: INFO: common: YAML file loaded successfully from: params.yaml:]\n",
      "[2025-09-16 02:40:17,214: INFO: common: Created directory at: artifacts:]\n",
      "[2025-09-16 02:40:17,215: INFO: common: Created directory at: artifacts/model_evaluation:]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/16 02:40:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run angry-shrew-612 at: https://dagshub.com/leksman/end_to_end_plant_vilage_project.mlflow/#/experiments/0/runs/ddee76f059634acc9bb5cdc6db91215a\n",
      "üß™ View experiment at: https://dagshub.com/leksman/end_to_end_plant_vilage_project.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    model_eval = ModelEvaluation(config=model_evaluation_config)\n",
    "    model_eval.evaluate_model()\n",
    "except Exception as e:\n",
    "    raise e    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e7bc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycondaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
